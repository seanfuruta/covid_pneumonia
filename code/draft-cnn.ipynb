{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nfrom tqdm import tqdm\nfrom glob import glob\nfrom keras.layers import *\nfrom keras.models import *\nfrom keras.utils import *\nimport numpy as np\nimport os","metadata":{"execution":{"iopub.status.busy":"2022-12-05T14:59:35.241319Z","iopub.execute_input":"2022-12-05T14:59:35.242123Z","iopub.status.idle":"2022-12-05T14:59:41.902235Z","shell.execute_reply.started":"2022-12-05T14:59:35.242047Z","shell.execute_reply":"2022-12-05T14:59:41.901105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Loading Files**","metadata":{}},{"cell_type":"code","source":"#  Use Validation set to test working model\n\ntrain_data = []\ntrain_labels = []\n\nwith open(plib.train_data_file, 'rb') as f:\n    train_data = np.load(f, allow_pickle=True)\n    train_labels = np.load(f, allow_pickle=True)","metadata":{"id":"gWHro7F_pM3O","execution":{"iopub.status.busy":"2022-12-05T14:59:41.906805Z","iopub.execute_input":"2022-12-05T14:59:41.907191Z","iopub.status.idle":"2022-12-05T14:59:44.276443Z","shell.execute_reply.started":"2022-12-05T14:59:41.907133Z","shell.execute_reply":"2022-12-05T14:59:44.275399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nval_data = []\nval_labels = []\n\nwith open(plib.val_data_file, 'rb') as f:\n    val_data = np.load(f, allow_pickle=True)\n    val_labels = np.load(f, allow_pickle=True)","metadata":{"id":"on7B8t2p6woL","outputId":"c3c503a3-43f4-4ffc-f269-1dd2c7157ceb","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntest_data = []\ntest_labels = []\n\nwith open(plib.test_data_file, 'rb') as f:\n    test_data = np.load(f, allow_pickle=True)\n    test_labels = np.load(f, allow_pickle=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dealing with Class Imbalance","metadata":{}},{"cell_type":"code","source":"from sklearn.utils import class_weight\n \n \nclass_weights = class_weight.compute_class_weight('balanced',\n                                                 np.unique(train_label),\n                                                 train_label)\nclass_weights","metadata":{"id":"9xCZ3EKV2-yx","execution":{"iopub.status.busy":"2022-12-05T15:03:52.447547Z","iopub.execute_input":"2022-12-05T15:03:52.448006Z","iopub.status.idle":"2022-12-05T15:03:53.434423Z","shell.execute_reply.started":"2022-12-05T15:03:52.447962Z","shell.execute_reply":"2022-12-05T15:03:53.432764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Residual Unit","metadata":{}},{"cell_type":"code","source":"def Residual_Unit(input_tensor, nb_of_input_channels, max_dilation, number_of_units):\n    \n  for i in range(number_of_units):\n    x1 = Conv2D(nb_of_input_channels*2, kernel_size = (1,1), strides = (1,1), padding='same', dilation_rate= (1,1), activation='relu')(input_tensor)\n    x1 = BatchNormalization()(x1)\n  \n    a = []\n\n    for i in range(1, max_dilation+1):\n      temp = DepthwiseConv2D( kernel_size=(3,3), dilation_rate = (i,i), padding = 'same', activation= 'relu')(x1)\n      temp = BatchNormalization()(temp)\n      a.append(temp)\n\n    x = Concatenate(axis= -1)(a)\n    x = Conv2D(nb_of_input_channels, kernel_size = (1,1), strides = (1,1), padding='same', dilation_rate= (1,1), activation='relu')(x)\n    x = BatchNormalization()(x)\n\n    x = Add()([x, input_tensor])\n\n    input_tensor = x\n  \n  return x\n","metadata":{"id":"-q5yOy9Tj1NT","execution":{"iopub.status.busy":"2022-12-05T15:03:59.263503Z","iopub.execute_input":"2022-12-05T15:03:59.264227Z","iopub.status.idle":"2022-12-05T15:03:59.279609Z","shell.execute_reply.started":"2022-12-05T15:03:59.263980Z","shell.execute_reply":"2022-12-05T15:03:59.278722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Shifter Unit","metadata":{}},{"cell_type":"code","source":"# Shifter Unit:\n\ndef Shifter_Unit(input_tensor, nb_of_input_channels, max_dilation):\n    x1 = Conv2D(nb_of_input_channels*4, kernel_size = (1,1), strides = (1,1), padding='same', dilation_rate= (1,1), activation='relu')(input_tensor)\n    x1 = BatchNormalization()(x1)\n\n    a = []\n\n    for i in range(1, max_dilation+1):\n      temp = DepthwiseConv2D( kernel_size=(3,3), dilation_rate = (i,i), padding = 'same', activation= 'relu')(x1)\n      temp = MaxPool2D(pool_size=(2,2))(temp)\n      temp = BatchNormalization()(temp)\n      a.append(temp)\n\n    x = Concatenate(axis= -1)(a)\n\n    x = Conv2D(nb_of_input_channels*2, kernel_size = (1,1), strides = (1,1), padding='same', dilation_rate= (1,1), activation='relu')(x)\n    x = BatchNormalization()(x)\n\n    return x","metadata":{"execution":{"iopub.status.busy":"2022-12-05T15:33:38.893673Z","iopub.execute_input":"2022-12-05T15:33:38.894524Z","iopub.status.idle":"2022-12-05T15:33:38.907363Z","shell.execute_reply.started":"2022-12-05T15:33:38.894422Z","shell.execute_reply":"2022-12-05T15:33:38.906227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Network128","metadata":{}},{"cell_type":"code","source":"from keras.optimizers import Adam","metadata":{"execution":{"iopub.status.busy":"2022-12-05T15:17:08.327800Z","iopub.execute_input":"2022-12-05T15:17:08.328245Z","iopub.status.idle":"2022-12-05T15:17:14.671978Z","shell.execute_reply.started":"2022-12-05T15:17:08.328184Z","shell.execute_reply":"2022-12-05T15:17:14.670908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Network:\n  \ndef Network128(input_shape, nb_class, depth):\n  xin = Input(shape= input_shape)\n\n  x = Conv2D(16, kernel_size = (5,5), strides= (1,1), padding = 'same', activation='relu')(xin)\n  x = BatchNormalization()(x)\n\n  x = Conv2D(32, kernel_size = (3,3), strides= (2,2), padding = 'same', activation='relu')(x)\n  x = BatchNormalization()(x)\n  \n##Max Dilation rate will be vary in the range (1,5). \n\n# Max Dilation rate is 5 for tensor (64x64x32)\n  x = Residual_Unit(input_tensor=x, nb_of_input_channels=32, max_dilation=5, number_of_units=depth)\n  x = Shifter_Unit(input_tensor=x, nb_of_input_channels=32, max_dilation=5)\n\n\n# Max Dilation rate is 4 for (32x32x64)\n  x = Residual_Unit(input_tensor=x, nb_of_input_channels=64, max_dilation=4, number_of_units=depth)\n  x = Shifter_Unit(input_tensor=x, nb_of_input_channels=64, max_dilation=4)\n\n# Max Dilation rate is 3 for (16x16x128)\n  x = Residual_Unit(input_tensor=x, nb_of_input_channels=128, max_dilation=3, number_of_units=depth)\n  x = Shifter_Unit(input_tensor=x, nb_of_input_channels=128, max_dilation=3)\n\n# Max Dilation rate is 2 for (8x8x256)\n  x = Residual_Unit(input_tensor=x, nb_of_input_channels=256, max_dilation=2, number_of_units=depth)\n\n  x = GlobalAveragePooling2D()(x)\n\n  x = Dense(128, activation='relu')(x)\n  x = Dense(64, activation='relu')(x)\n\n  x = Dense(nb_class, activation= 'softmax')(x)\n\n  model = Model(xin, x)\n\n  model.compile(loss='categorical_crossentropy', optimizer = Adam(lr = 1e-3), metrics = ['accuracy'])\n\n  return model","metadata":{"execution":{"iopub.status.busy":"2022-12-05T15:04:26.191859Z","iopub.execute_input":"2022-12-05T15:04:26.192296Z","iopub.status.idle":"2022-12-05T15:04:26.206887Z","shell.execute_reply.started":"2022-12-05T15:04:26.192247Z","shell.execute_reply":"2022-12-05T15:04:26.205448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Custom Callback","metadata":{}},{"cell_type":"code","source":"# plot confusion matrix\n\nimport itertools\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nimport pandas.util.testing as tm\nfrom sklearn import metrics\nimport seaborn as sns\nsns.set()\n\nplt.rcParams[\"font.family\"] = 'DejaVu Sans'\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues,\n                          save = False):\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.grid(b=False)\n    if save == True:\n      plt.savefig('Confusion Matrix.png', dpi = 900)","metadata":{"execution":{"iopub.status.busy":"2022-12-05T15:17:14.676722Z","iopub.execute_input":"2022-12-05T15:17:14.677123Z","iopub.status.idle":"2022-12-05T15:17:14.694940Z","shell.execute_reply.started":"2022-12-05T15:17:14.677062Z","shell.execute_reply":"2022-12-05T15:17:14.693647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test model performance\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\n\n\ndef test_model(model, test_generator, y_test, class_labels, cm_normalize=True, \\\n                 print_cm=True):\n    \n    # BS = 16\n    results = dict()\n    \n\n    print('Predicting test data')\n    test_start_time = datetime.now()\n    y_pred_original = model.predict_generator(test_generator,verbose=1)\n\n    y_pred = np.argmax(y_pred_original, axis = 1)\n    \n    test_end_time = datetime.now()\n    print('Done \\n \\n')\n    results['testing_time'] = test_end_time - test_start_time\n    print('testing time(HH:MM:SS:ms) - {}\\n\\n'.format(results['testing_time']))\n    results['predicted'] = y_pred\n    y_test = y_test.astype(int) # sparse form not categorical\n    \n\n    # balanced_accuracy\n    from sklearn.metrics import balanced_accuracy_score\n    balanced_accuracy = balanced_accuracy_score(y_true=y_test, y_pred=y_pred)\n    print('---------------------')\n    print('| Balanced Accuracy  |')\n    print('---------------------')\n    print('\\n    {}\\n\\n'.format(balanced_accuracy))\n\n    \n    # calculate overall accuracty of the model\n    accuracy = metrics.accuracy_score(y_true=y_test, y_pred=y_pred)\n    # store accuracy in results\n    results['accuracy'] = accuracy\n    print('---------------------')\n    print('|      Accuracy      |')\n    print('---------------------')\n    print('\\n    {}\\n\\n'.format(accuracy))\n    \n\n    # get classification report\n    print('-------------------------')\n    print('| Classifiction Report |')\n    print('-------------------------')\n    classification_report = metrics.classification_report(y_test, y_pred)\n    # store report in results\n    results['classification_report'] = classification_report\n    print(classification_report)\n    \n    \n    \n    # confusion matrix\n    cm = metrics.confusion_matrix(y_test, y_pred)\n    results['confusion_matrix'] = cm\n    if print_cm: \n        print('--------------------')\n        print('| Confusion Matrix |')\n        print('--------------------')\n        print('\\n {}'.format(cm))\n        \n    # plot confusin matrix\n    plt.figure(figsize=(6,4))\n    plt.grid(b=False)\n    plot_confusion_matrix(cm, classes=class_labels, normalize=True, title='Normalized confusion matrix')\n    plt.show()\n    \n\n    \n    # add the trained  model to the results\n    results['model'] = model\n    \n    return\n\n\nfrom keras.callbacks import Callback\nclass MyLogger(Callback):\n  \n  def __init__(self, test_generator, y_test, class_labels):\n    super(MyLogger, self).__init__()\n    self.test_generator = test_generator\n    self.y_test = y_test\n    self.class_labels = class_labels\n    \n  def on_epoch_end(self, epoch, logs=None):\n    test_model(self.model, self.test_generator, self.y_test, self.class_labels)","metadata":{"execution":{"iopub.status.busy":"2022-12-05T15:17:46.693007Z","iopub.execute_input":"2022-12-05T15:17:46.693471Z","iopub.status.idle":"2022-12-05T15:17:46.713294Z","shell.execute_reply.started":"2022-12-05T15:17:46.693392Z","shell.execute_reply":"2022-12-05T15:17:46.711277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# One Hot Encoding the labels","metadata":{}},{"cell_type":"code","source":"from keras.utils import to_categorical\ntrain_label = to_categorical(train_label, num_classes= 3)\ntest_label  = to_categorical(test_label, num_classes = 3)","metadata":{"id":"cTJ9tv0utCkq","execution":{"iopub.status.busy":"2022-12-05T15:17:57.258868Z","iopub.execute_input":"2022-12-05T15:17:57.259597Z","iopub.status.idle":"2022-12-05T15:17:57.734557Z","shell.execute_reply.started":"2022-12-05T15:17:57.259524Z","shell.execute_reply":"2022-12-05T15:17:57.732607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ImageDataGenerator","metadata":{}},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import load_model\nfrom keras.callbacks import *\n\n\ntrain_datagen = ImageDataGenerator(rescale = 1/255,\n                                  width_shift_range = 0.1,\n                                  height_shift_range = 0.1,\n                                  fill_mode = 'constant',\n                                  zoom_range = 0.2,\n                                  rotation_range = 30)\n\nval_datagen = ImageDataGenerator(rescale = 1/255)\n\ntrain_generator = train_datagen.flow(train_data,\n                                     train_label, \n                                     batch_size = 16, \n                                     shuffle = True)\n\nval_generator = val_datagen.flow(val_data,\n                                 val_label,\n                                 batch_size = 16,\n                                 shuffle = False)","metadata":{"id":"CFqUbhNwd-wD","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Vizualization After Augmentation","metadata":{}},{"cell_type":"code","source":"images, labels = train_generator.next()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_row = 3\nn_col = 5\n\nfig, ax = plt.subplots(n_row, n_col, figsize = (n_col*3, n_row*3), constrained_layout = True)\n\nfor row in tqdm(range(n_row)):\n    \n    for col in range(n_col):\n        \n        ax[row][col].imshow(images[row*n_col + col,:,:,0], cmap = 'bone')\n        ax[row][col].set_xticks([])\n        ax[row][col].set_yticks([])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Callback","metadata":{}},{"cell_type":"code","source":"def get_callbacks():\n    \n    filepath = 'best_model_multiclass_128.h5'\n    callback1 = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n    callback2 = MyLogger(val_generator, \n                         y_test = np.argmax(test_label, axis = 1),\n                         class_labels = ['Normal', 'Viral', 'Bacterial'])\n    \n    callback3 = CSVLogger('Multiclass_Log_128.csv')\n\n    return [callback1 ,callback2, callback3]","metadata":{"id":"sSDuzmTJzlbZ","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"model = Network128(input_shape = (128, 128, 1), nb_class = 3, depth = 5)\nmodel.summary() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plotting Model","metadata":{}},{"cell_type":"code","source":"plot_model(model, show_shapes=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit_generator(train_generator,\n                              steps_per_epoch = len(train_data) // 16,\n                              validation_data=val_generator,\n                              validation_steps= len(test_data)// 16,\n                              class_weight =class_weights,\n                              epochs = 70,\n                              callbacks = get_callbacks(),\n                              verbose = 1\n                              )","metadata":{"id":"ivEn3qjDfx0Z","outputId":"e9fd7c61-bd2a-4d02-f5e7-acc1fedcd68d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading Best Model","metadata":{}},{"cell_type":"code","source":"from keras.models import load_model\nbest_model = load_model('best_model_multiclass_128.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Best Model Performance","metadata":{}},{"cell_type":"code","source":"classes = {'Normal':0, 'COVID-19':1, 'Non-COVID':2}\nclass_labels = ['Normal', 'COVID-19', 'Non-COVID']\ntest_model(best_model, \n           val_generator,\n           y_test = np.argmax(test_label, axis = 1),\n           class_labels = class_labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plotting EpochPlot","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nacc = model.history.history['accuracy']\nval_acc = model.history.history['val_accuracy']\nloss = model.history.history['loss']\nval_loss = model.history.history['val_loss']\n\nepochs = range(0,len(acc))\nfig = plt.gcf()\nfig.set_size_inches(16, 8)\n\nplt.plot(epochs, acc, 'r', label='Training accuracy',marker = \"o\")\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy',marker = \"o\")\nplt.title('Training and validation accuracy')\nplt.xticks(np.arange(0, len(acc), 10))\nplt.legend(loc=0)\nplt.figure()\n\nfig = plt.gcf()\nfig.set_size_inches(16, 8)\nplt.plot(epochs, loss, 'r', label='Training Loss',marker = \"o\")\nplt.plot(epochs, val_loss, 'b', label='Validation Loss',marker = \"o\")\nplt.title('Training and validation Loss')\nplt.xticks(np.arange(0, len(acc), 10))\nplt.legend(loc=0)\n#plt.savefig('Multiclass Model .png')\nplt.figure()\nplt.show()\n","metadata":{"id":"LLrmp-WXFcKm","outputId":"9c150318-6d03-4360-b385-5a654eaa322a","trusted":true},"execution_count":null,"outputs":[]}]}